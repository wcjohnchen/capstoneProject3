{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'mean_absolute_percentage_error' from 'sklearn.metrics' (C:\\Users\\wcjohnchen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d96aac4720d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'mean_absolute_percentage_error' from 'sklearn.metrics' (C:\\Users\\wcjohnchen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "##### import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, Activation, Dropout, Dense, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### definition\n",
    "def plot_graph(x, y, title, xlabels, ymin, ymax):\n",
    "    ax.plot(x, y, color='steelblue')\n",
    "    ax.set_ylim(ymin,ymax)\n",
    "    ax.set_xlim(-5,150)\n",
    "    ax.set_xlabel('Year-Month')\n",
    "    ax.set_ylabel('Averaged delayed time per late flight departure (minutes)')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(10))\n",
    "    plt.xticks(np.arange(0, 145, 12))\n",
    "    ax.set_xticklabels(xlabels)\n",
    "    plt.grid(alpha=0.15)\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_graph_predict(x, y, x2, y2, title, xlabels, ymin, ymax):\n",
    "    ax.plot(x, y, color='crimson')\n",
    "    ax.plot(x2, y2, color='steelblue')\n",
    "    ax.set_ylim(ymin,ymax)\n",
    "    ax.set_xlim(-5,150)\n",
    "    ax.set_xlabel('Year-Month')\n",
    "    ax.set_ylabel('Averaged delayed time per late flight departure (minutes)')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(10))\n",
    "    plt.xticks(np.arange(0, 145, 12))\n",
    "    ax.set_xticklabels(xlabels)\n",
    "    plt.grid(alpha=0.15)\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_graph_predict2(x, y, x2, y2, title, xlabels, ymin, ymax):\n",
    "    ci = 2*np.std(y)\n",
    "    ax.plot(x2, y2, color='steelblue')\n",
    "    ax.fill_between(x, (y-ci), (y+ci), color='crimson', alpha=.3)\n",
    "    ax.set_ylim(ymin,ymax)\n",
    "    ax.set_xlim(-5,150)\n",
    "    ax.set_xlabel('Year-Month')\n",
    "    ax.set_ylabel('Averaged delayed time per late flight departure (minutes)')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(10))\n",
    "    plt.xticks(np.arange(0, 145, 12))\n",
    "    ax.set_xticklabels(xlabels)\n",
    "    plt.grid(alpha=0.15)\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_SimpleRNN_model(n_steps_in, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(SimpleRNN(32, activation='tanh', return_sequences=True, input_shape=(n_steps_in, n_features))))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(SimpleRNN(64, activation='tanh', return_sequences=True)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(SimpleRNN(128, activation='tanh', return_sequences=True)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(SimpleRNN(256, activation='tanh', return_sequences=True)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(SimpleRNN(1024, activation='tanh', return_sequences=True)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(SimpleRNN(1024, activation='tanh', return_sequences=False)))\n",
    "    model.add(Dropout(0.1))     \n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(Dense(units=n_steps_out))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    return model\n",
    "\n",
    "def build_LSTM_model1(n_steps_in, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(32, activation='tanh', return_sequences=True, input_shape=(n_steps_in, n_features))))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(64, activation='tanh', return_sequences=True)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(128, activation='tanh', return_sequences=True)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(256, activation='tanh', return_sequences=True)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(512, activation='tanh', return_sequences=True)))\n",
    "    model.add(Dropout(0.1))    \n",
    "\n",
    "    model.add(Bidirectional(LSTM(1024, activation='tanh', return_sequences=False)))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(Dense(units=n_steps_out))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    return model\n",
    "\n",
    "def build_LSTM_model2(n_steps_in, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(32, activation='tanh', return_sequences=True, input_shape=(n_steps_in, n_features))))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(64, activation='tanh', return_sequences=True)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(128, activation='tanh', return_sequences=True)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(256, activation='tanh', return_sequences=True)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(1024, activation='tanh', return_sequences=True)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(1024, activation='tanh', return_sequences=False)))\n",
    "    model.add(Dropout(0.1))     \n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dense(units=n_steps_out))\n",
    "    model.add(Activation(\"linear\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File modified_data.csv does not exist: 'modified_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ede77f5880ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'modified_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File modified_data.csv does not exist: 'modified_data.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('modified_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southwest = data[data['OP_CARRIER'] == 'Southwest Airlines']\n",
    "united = data[data['OP_CARRIER'] == 'United Airlines']\n",
    "alaska = data[data['OP_CARRIER'] == 'Alaska Airlines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_delay = southwest.groupby(['year', 'month'])[['DEP_DELAY']].sum()\n",
    "ua_delay = united.groupby(['year', 'month'])[['DEP_DELAY']].sum()\n",
    "alaska_delay = alaska.groupby(['year', 'month'])[['DEP_DELAY']].sum()\n",
    "all_delay = data.groupby(['year', 'month'])[['DEP_DELAY']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### count number of flights per day\n",
    "sw_count = southwest.groupby(['year', 'month'])[['DEP_DELAY']].count()\n",
    "ua_count = united.groupby(['year', 'month'])[['DEP_DELAY']].count()\n",
    "alaska_count = alaska.groupby(['year', 'month'])[['DEP_DELAY']].count()\n",
    "all_count = data.groupby(['year', 'month'])[['DEP_DELAY']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### averaged delayed time per late flight departure\n",
    "sw = sw_delay/sw_count\n",
    "ua = ua_delay/ua_count\n",
    "ak = alaska_delay/alaska_count\n",
    "total = all_delay/all_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sw.index.tolist()\n",
    "sw_index=[]\n",
    "for i in range(len(s)):\n",
    "    for j in range(len(s[0])-1):\n",
    "        date = str(s[i][j])+str('-')+str(s[i][j+1])\n",
    "        sw_index.append(date)\n",
    "\n",
    "u = ua.index.tolist()\n",
    "ua_index=[]\n",
    "for i in range(len(u)):\n",
    "    for j in range(len(u[0])-1):\n",
    "        date = str(u[i][j])+str('-')+str(u[i][j+1])\n",
    "        ua_index.append(date)\n",
    "        \n",
    "a = ak.index.tolist()\n",
    "ak_index=[]\n",
    "for i in range(len(a)):\n",
    "    for j in range(len(a[0])-1):\n",
    "        date = str(a[i][j])+str('-')+str(a[i][j+1])\n",
    "        ak_index.append(date)\n",
    "        \n",
    "t = total.index.tolist()\n",
    "total_index=[]\n",
    "for i in range(len(t)):\n",
    "    for j in range(len(t[0])-1):\n",
    "        date = str(t[i][j])+str('-')+str(t[i][j+1])\n",
    "        total_index.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### data, split into train and test\n",
    "all_lst = np.array(total['DEP_DELAY'].values.tolist())\n",
    "train_all = all_lst[:int(len(all_lst)*0.8)]\n",
    "test_all = all_lst[int(len(all_lst)*0.8):]\n",
    "\n",
    "swlst = np.array(sw['DEP_DELAY'].values.tolist())\n",
    "train_sw = swlst[:int(len(swlst)*0.8)]\n",
    "test_sw = swlst[int(len(swlst)*0.8):]\n",
    "\n",
    "ualst = np.array(ua['DEP_DELAY'].values.tolist())\n",
    "train_ua = ualst[:int(len(ualst)*0.8)]\n",
    "test_ua = ualst[int(len(ualst)*0.8):]\n",
    "\n",
    "aklst = np.array(ak['DEP_DELAY'].values.tolist())\n",
    "train_ak = aklst[:int(len(ak)*0.8)]\n",
    "test_ak = aklst[int(len(ak)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### generate x labels\n",
    "y2019 = ['2019' for i in range(12)]\n",
    "y2020 = ['2020' for i in range(12)]\n",
    "y2021 = ['2021' for i in range(2)]\n",
    "string = y2019+y2020+y2021\n",
    "\n",
    "mm = np.arange(1,13).tolist()\n",
    "mm = mm*2\n",
    "for sublist in ['1','2']:\n",
    "    mm.append(sublist)\n",
    "\n",
    "swpredict_index=[]\n",
    "for i in range(len(mm)):\n",
    "    date = str(string[i])+str('-')+str(mm[i])\n",
    "    swpredict_index.append(date)\n",
    "swpredict_index\n",
    "\n",
    "predict_sw_index = sw_index + swpredict_index\n",
    "\n",
    "zero = [0 for i in range(146)]\n",
    "\n",
    "xlabel=[]\n",
    "for i in range(0,len(predict_sw_index),12):\n",
    "    xlabel.append(predict_sw_index[i])\n",
    "xlabel.append('2021-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### plot time series\n",
    "x = total_index\n",
    "y = all_lst\n",
    "xlabels = xlabel\n",
    "ymin = 15\n",
    "ymax = 50\n",
    "#title = 'All Airlines, 2009-2018'\n",
    "title =''\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "plot_graph(x, y, title, xlabels, ymin, ymax)\n",
    "#fig.savefig('all_origin.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### plot time series\n",
    "x = sw_index\n",
    "y = swlst\n",
    "ymin = 10\n",
    "ymax = 45\n",
    "xlabels = xlabel\n",
    "#title = 'Southwest Airlines, 2009-2018'\n",
    "title =''\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "plot_graph(x, y, title, xlabels, ymin, ymax)\n",
    "#fig.savefig('sw_origin.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### plot time series\n",
    "x = ak_index\n",
    "y = aklst\n",
    "ymin = 10\n",
    "ymax = 45\n",
    "xlabels = xlabel\n",
    "#title = 'Southwest Airlines, 2009-2018'\n",
    "title =''\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "plot_graph(x, y, title, xlabels, ymin, ymax)\n",
    "#fig.savefig('ak_origin.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LSTM Model ##\n",
    "##### Southwest Airlines\n",
    "raw_seq = swlst[:94]\n",
    "epoch = 100\n",
    "learn_rate = 0.0001\n",
    "\n",
    "##### number of previous steps, number of predicted future steps\n",
    "n_steps_in, n_steps_out = 66, 24\n",
    "\n",
    "##### split into samples\n",
    "X_sw, y_sw = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "print(X_sw.shape)\n",
    "print(y_sw.shape)\n",
    "\n",
    "##### reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X_sw = X_sw.reshape((X_sw.shape[0], X_sw.shape[1], n_features))\n",
    "\n",
    "callback = ModelCheckpoint(filepath='model00sw.h5', monitor='mse', mode='min', save_best_only=True)\n",
    "\n",
    "test_ci=[]\n",
    "future_ci=[]\n",
    "for i in range(3):\n",
    "    ##### build model\n",
    "    model_sw = build_LSTM_model2(n_steps_in, n_features)\n",
    "    \n",
    "    ##### compile model\n",
    "    optimizer = Adam(learning_rate=learn_rate)\n",
    "    model_sw.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    \n",
    "    ##### fit model\n",
    "    history_sw = model_sw.fit(X_sw, y_sw, epochs=epoch, verbose=1, callbacks=[callback])\n",
    "    \n",
    "    ##### predict test data\n",
    "    x_input_sw = swlst[(94-n_steps_in):94]\n",
    "    x_input_sw = x_input_sw.reshape((1, n_steps_in, n_features))\n",
    "    p = model_sw.predict(x_input_sw, verbose=0)\n",
    "    test_ci.append(p[0])\n",
    "    \n",
    "    ##### predict future data\n",
    "    new_predict_sw = model_sw.predict(np.append(X_sw,y_sw)[24:][np.newaxis,:,np.newaxis])\n",
    "\n",
    "    ##### append values\n",
    "    new_pred_sw = np.append(swlst[len(swlst)-1], new_predict_sw)\n",
    "    future_ci.append(new_pred_sw)\n",
    "\n",
    "model_sw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_mean = np.mean(future_ci, axis=0)\n",
    "ci_test = np.mean(test_ci, axis=0)\n",
    "new_pred_sw = ci_mean\n",
    "y_pred_sw = ci_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### calculate mean squared error and mean absolute percentage error\n",
    "##### southwest\n",
    "mse_sw = mean_squared_error(swlst[94:], y_pred_sw)\n",
    "rmse_sw = np.sqrt(mse_sw)\n",
    "print(rmse_sw)\n",
    "map_sw = mean_absolute_percentage_error(swlst[94:], y_pred_sw)*100\n",
    "print(map_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Southwest Airlines\n",
    "##### plot test prediction\n",
    "x = np.arange(24)+92\n",
    "y = y_pred_sw\n",
    "x2 = np.arange(len(swlst))\n",
    "y2 = swlst\n",
    "#x2 = np.arange(95)\n",
    "#y2 = swlst[:95]\n",
    "ymin = 10\n",
    "ymax = 45\n",
    "xlabels = xlabel\n",
    "#title = 'Southwest Airlines, 2009-2018'\n",
    "title =''\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "plot_graph_predict(x, y, x2, y2, title, xlabels, ymin, ymax)\n",
    "#fig.savefig('sw_predict_test3.png')\n",
    "\n",
    "##### plot future prediction\n",
    "x = np.arange(25)+117\n",
    "y = new_pred_sw\n",
    "x2 = sw_index\n",
    "y2 = swlst\n",
    "ymin = 10\n",
    "ymax = 45\n",
    "xlabels = xlabel\n",
    "#title = 'Southwest Airlines, 2009-2018'\n",
    "title =''\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "plot_graph_predict2(x, y, x2, y2, title, xlabels, ymin, ymax)\n",
    "#fig.savefig('sw_predict_future_spread.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### graph MSE\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(history_sw.history['mse'], color='red')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "plt.legend(['Train'], frameon=False)\n",
    "plt.show()\n",
    "#fig.savefig('sw_mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LSTM Model\n",
    "##### Alaska Airlines\n",
    "raw_seq = train_ak\n",
    "epoch = 20\n",
    "learn_rate = 0.001\n",
    "\n",
    "##### number of previous steps, number of predicted future steps\n",
    "n_steps_in, n_steps_out = 66, 24\n",
    "\n",
    "##### split into samples\n",
    "X_ak, y_ak = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "\n",
    "##### reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X_ak = X_ak.reshape((X_ak.shape[0], X_ak.shape[1], n_features))\n",
    "\n",
    "#callback = ModelCheckpoint(filepath='model00.h5', monitor='mse', mode='min', save_best_only=True)\n",
    "\n",
    "test_ci=[]\n",
    "future_ci=[]\n",
    "for i in range(3):\n",
    "    ##### build model\n",
    "    model_ak = build_LSTM_model1(n_steps_in, n_features)\n",
    "    \n",
    "    ##### compile model\n",
    "    optimizer = Adam(learning_rate=learn_rate)\n",
    "    model_ak.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    \n",
    "    ##### fit model\n",
    "    #history_alaska = model_sw.fit(X_ak, y_ak, epochs=epoch, verbose=1, callbacks=[callback])\n",
    "    history_alaska = model_ak.fit(X_ak, y_ak, epochs=epoch, verbose=1)\n",
    "\n",
    "    ##### predict test data\n",
    "    x_input_ak = aklst[(94-n_steps_in):94]\n",
    "    x_input_ak = x_input_ak.reshape((1, n_steps_in, n_features))\n",
    "    p = model_ak.predict(x_input_ak, verbose=0)\n",
    "    test_ci.append(p[0])\n",
    "    \n",
    "    ##### predict future data\n",
    "    new_predict_ak = model_ak.predict(np.append(X_ak,y_ak)[24:][np.newaxis,:,np.newaxis])\n",
    "\n",
    "    ##### append values\n",
    "    new_pred_ak = np.append(aklst[len(aklst)-1], new_predict_ak)\n",
    "    future_ci.append(new_pred_ak)\n",
    "\n",
    "model_ak.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_mean = np.mean(future_ci, axis=0)\n",
    "ci_test = np.mean(test_ci, axis=0)\n",
    "new_pred_ak = ci_mean\n",
    "y_pred_ak = ci_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### calculate mean squared error and mean absolute percentage error\n",
    "##### southwest\n",
    "mse_ak = mean_squared_error(aklst[94:], y_pred_ak)\n",
    "rmse_ak = np.sqrt(mse_ak)\n",
    "print(rmse_ak)\n",
    "map_ak = mean_absolute_percentage_error(aklst[94:], y_pred_ak)*100\n",
    "print(map_ak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Alaska Airlines\n",
    "##### plot test prediction\n",
    "x = np.arange(24)+92\n",
    "y = y_pred_ak\n",
    "x2 = np.arange(len(aklst))\n",
    "y2 = aklst\n",
    "#x2 = np.arange(95)\n",
    "#y2 = swlst[:95]\n",
    "ymin = 10\n",
    "ymax = 45\n",
    "xlabels = xlabel\n",
    "#title = 'Alaska Airlines, 2009-2018'\n",
    "title =''\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "plot_graph_predict(x, y, x2, y2, title, xlabels, ymin, ymax)\n",
    "#fig.savefig('ak_predict_test3.png')\n",
    "\n",
    "##### plot future prediction\n",
    "x = np.arange(25)+117\n",
    "y = new_pred_ak\n",
    "x2 = ak_index\n",
    "y2 = aklst\n",
    "ymin = 10\n",
    "ymax = 45\n",
    "xlabels = xlabel\n",
    "#title = 'Alaska Airlines, 2009-2018'\n",
    "title =''\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "plot_graph_predict2(x, y, x2, y2, title, xlabels, ymin, ymax)\n",
    "#fig.savefig('ak_predict_future_spread.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### graph MSE\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(history_alaska.history['mse'], color='red')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "plt.legend(['Train'], frameon=False)\n",
    "plt.show()\n",
    "#fig.savefig('ak_mse.png')history_alaska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LSTM Model\n",
    "##### All Airlines\n",
    "raw_seq = all_lst[:94]\n",
    "epoch = 20\n",
    "learn_rate = 0.001\n",
    "\n",
    "##### number of previous steps, number of predicted future steps\n",
    "n_steps_in, n_steps_out = 66, 24\n",
    "\n",
    "##### split into samples\n",
    "X_a, y_a = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "\n",
    "##### reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X_a = X_a.reshape((X_a.shape[0], X_a.shape[1], n_features))\n",
    "\n",
    "#callback = ModelCheckpoint(filepath='model00.h5', monitor='mse', mode='min', save_best_only=True)\n",
    "\n",
    "test_ci=[]\n",
    "future_ci=[]\n",
    "for i in range(3):\n",
    "    ##### build model\n",
    "    model_a = build_LSTM_model1(n_steps_in, n_features)\n",
    "    \n",
    "    ##### compile model\n",
    "    optimizer = Adam(learning_rate=learn_rate)\n",
    "    model_a.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    \n",
    "    ##### fit model\n",
    "    #history_a = model_sw.fit(X_a, y_a, epochs=epoch, verbose=1, callbacks=[callback])\n",
    "    history_a = model_a.fit(X_a, y_a, epochs=epoch, verbose=1)\n",
    "\n",
    "    ##### predict test data\n",
    "    x_input_a = aklst[(94-n_steps_in):94]\n",
    "    x_input_a = x_input_a.reshape((1, n_steps_in, n_features))\n",
    "    p = model_a.predict(x_input_a, verbose=0)\n",
    "    test_ci.append(p[0])\n",
    "    \n",
    "    ##### predict future data\n",
    "    new_predict_a = model_a.predict(np.append(X_a,y_a)[24:][np.newaxis,:,np.newaxis])\n",
    "\n",
    "    ##### append values\n",
    "    new_pred_a = np.append(all_lst[len(all_lst)-1], new_predict_a)\n",
    "    future_ci.append(new_pred_a)\n",
    "\n",
    "model_a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_mean = np.mean(future_ci, axis=0)\n",
    "ci_test = np.mean(test_ci, axis=0)\n",
    "new_pred_a = ci_mean\n",
    "y_pred_a = ci_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### all\n",
    "mse_a = mean_squared_error(all_lst[94:], ci[2])\n",
    "rmse_a = np.sqrt(mse_a)\n",
    "print(rmse_a)\n",
    "map_a = mean_absolute_percentage_error(all_lst[94:], ci[2])*100\n",
    "print(map_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### All Airlines\n",
    "##### plot test prediction\n",
    "x = np.arange(24)+92\n",
    "y = y_pred_a\n",
    "x2 = np.arange(len(all_lst))\n",
    "y2 = all_lst\n",
    "ymin = 15\n",
    "ymax = 50\n",
    "xlabels = xlabel\n",
    "#title = 'All Airlines, 2009-2018'\n",
    "title =''\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "plot_graph_predict(x, y, x2, y2, title, xlabels, ymin, ymax)\n",
    "#fig.savefig('all_predict_test3.png')\n",
    "\n",
    "##### plot future prediction\n",
    "x = np.arange(25)+117\n",
    "y = new_pred_a\n",
    "x2 = total_index\n",
    "y2 = all_lst\n",
    "ymin = 15\n",
    "ymax = 50\n",
    "xlabels = xlabel\n",
    "#title = 'All Airlines, 2009-2018'\n",
    "title =''\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "plot_graph_predict2(x, y, x2, y2, title, xlabels, ymin, ymax)\n",
    "#fig.savefig('all_predict_future_spread.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### graph MSE\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(history_a.history['mse'], color='red')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "plt.legend(['Train'], frameon=False)\n",
    "plt.show()\n",
    "#fig.savefig('all_mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### load model\n",
    "#model_sw = models.load_model('model00.h5')\n",
    "#model_sw.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
